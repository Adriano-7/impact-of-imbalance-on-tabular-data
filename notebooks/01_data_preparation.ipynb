{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04a5d143",
   "metadata": {},
   "source": [
    "# 1. Data Loading and Initial Setup\n",
    "\n",
    "1.  Load and clean the raw data using MICE imputation.\n",
    "2.  Create a single, hold-out test set.\n",
    "3.  From the main training set, generate multiple training datasets with varying **imbalance ratios (IR)** by undersampling the majority class.\n",
    "4.  For each IR, create **multiple repetitions** with different random samples of the minority class.\n",
    "5.  For each IR and repetition, create a size-matched **control dataset** with the original class ratio.\n",
    "6.  Preprocess and save all generated datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9894605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and loading the raw dataset...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m PROCESSED_PATH.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFetching and loading the raw dataset...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m mammographic_mass = \u001b[43mfetch_ucirepo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m=\u001b[49m\u001b[32;43m161\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m X_features = mammographic_mass.data.features\n\u001b[32m     24\u001b[39m y_target = mammographic_mass.data.targets\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/ucimlrepo/fetch.py:68\u001b[39m, in \u001b[36mfetch_ucirepo\u001b[39m\u001b[34m(name, id)\u001b[39m\n\u001b[32m     66\u001b[39m data = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     response = \u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mssl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_default_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcafile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcertifi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m     data = json.load(response)\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (urllib.error.URLError, urllib.error.HTTPError):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/urllib/request.py:189\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, context)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    188\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/urllib/request.py:489\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    486\u001b[39m     req = meth(req)\n\u001b[32m    488\u001b[39m sys.audit(\u001b[33m'\u001b[39m\u001b[33murllib.Request\u001b[39m\u001b[33m'\u001b[39m, req.full_url, req.data, req.headers, req.get_method())\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[32m    492\u001b[39m meth_name = protocol+\u001b[33m\"\u001b[39m\u001b[33m_response\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/urllib/request.py:506\u001b[39m, in \u001b[36mOpenerDirector._open\u001b[39m\u001b[34m(self, req, data)\u001b[39m\n\u001b[32m    503\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    505\u001b[39m protocol = req.type\n\u001b[32m--> \u001b[39m\u001b[32m506\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m                          \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m_open\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m    509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/urllib/request.py:466\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    465\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    467\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    468\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/urllib/request.py:1367\u001b[39m, in \u001b[36mHTTPSHandler.https_open\u001b[39m\u001b[34m(self, req)\u001b[39m\n\u001b[32m   1366\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[32m-> \u001b[39m\u001b[32m1367\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1368\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/urllib/request.py:1319\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1317\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1318\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1319\u001b[39m         \u001b[43mh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1320\u001b[39m \u001b[43m                  \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTransfer-encoding\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1321\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[32m   1322\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/http/client.py:1338\u001b[39m, in \u001b[36mHTTPConnection.request\u001b[39m\u001b[34m(self, method, url, body, headers, encode_chunked)\u001b[39m\n\u001b[32m   1335\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, url, body=\u001b[38;5;28;01mNone\u001b[39;00m, headers={}, *,\n\u001b[32m   1336\u001b[39m             encode_chunked=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   1337\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1338\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/http/client.py:1384\u001b[39m, in \u001b[36mHTTPConnection._send_request\u001b[39m\u001b[34m(self, method, url, body, headers, encode_chunked)\u001b[39m\n\u001b[32m   1380\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(body, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m   1381\u001b[39m     \u001b[38;5;66;03m# RFC 2616 Section 3.7.1 says that text default has a\u001b[39;00m\n\u001b[32m   1382\u001b[39m     \u001b[38;5;66;03m# default charset of iso-8859-1.\u001b[39;00m\n\u001b[32m   1383\u001b[39m     body = _encode(body, \u001b[33m'\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1384\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/http/client.py:1333\u001b[39m, in \u001b[36mHTTPConnection.endheaders\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1332\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[32m-> \u001b[39m\u001b[32m1333\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/http/client.py:1093\u001b[39m, in \u001b[36mHTTPConnection._send_output\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1091\u001b[39m msg = \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mself\u001b[39m._buffer)\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer[:]\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1096\u001b[39m \n\u001b[32m   1097\u001b[39m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n\u001b[32m   1098\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(message_body, \u001b[33m'\u001b[39m\u001b[33mread\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m   1099\u001b[39m         \u001b[38;5;66;03m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[32m   1100\u001b[39m         \u001b[38;5;66;03m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[32m   1101\u001b[39m         \u001b[38;5;66;03m# files to be taken into account.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/http/client.py:1037\u001b[39m, in \u001b[36mHTTPConnection.send\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.sock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1036\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_open:\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1038\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1039\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m NotConnected()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/http/client.py:1472\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1469\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1470\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mConnect to a host on a given (SSL) port.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1472\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1474\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tunnel_host:\n\u001b[32m   1475\u001b[39m         server_hostname = \u001b[38;5;28mself\u001b[39m._tunnel_host\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/http/client.py:1003\u001b[39m, in \u001b[36mHTTPConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1001\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[39;00m\n\u001b[32m   1002\u001b[39m sys.audit(\u001b[33m\"\u001b[39m\u001b[33mhttp.client.connect\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m.port)\n\u001b[32m-> \u001b[39m\u001b[32m1003\u001b[39m \u001b[38;5;28mself\u001b[39m.sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[38;5;66;03m# Might fail in OSs that don't implement TCP_NODELAY\u001b[39;00m\n\u001b[32m   1006\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/socket.py:849\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, all_errors)\u001b[39m\n\u001b[32m    847\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[32m    848\u001b[39m     sock.bind(source_address)\n\u001b[32m--> \u001b[39m\u001b[32m849\u001b[39m \u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[32m    851\u001b[39m exceptions.clear()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.utils import resample\n",
    "from pathlib import Path\n",
    "\n",
    "RAW_PATH = Path(\"../data/raw/mammographic_mass.csv\")\n",
    "PROCESSED_PATH = Path(\"../data/processed/\")\n",
    "TARGET_FEATURE = 'Severity'\n",
    "RANDOM_STATE = 42\n",
    "IMBALANCE_RATIOS = [1, 5, 10, 20, 50, 100] \n",
    "N_REPETITIONS = 3  \n",
    "\n",
    "RAW_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "PROCESSED_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Fetching and loading the raw dataset...\")\n",
    "mammographic_mass = fetch_ucirepo(id=161)\n",
    "X_features = mammographic_mass.data.features\n",
    "y_target = mammographic_mass.data.targets\n",
    "df_raw = pd.concat([X_features, y_target], axis=1)\n",
    "df_raw.to_csv(RAW_PATH, index=False)\n",
    "print(f\"Raw dataset loaded and saved. Shape: {df_raw.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9e24a5",
   "metadata": {},
   "source": [
    "# 2. Data Cleaning: Imputing Missing Values\n",
    "\n",
    "As determined in the EDA, we use MICE to impute missing values to avoid introducing bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5534acab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting MICE imputation...\n",
      "Data cleaned and imputed. Shape: (961, 6)\n",
      "\n",
      "Missing values after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "cols_to_impute = ['BI-RADS', 'Age', 'Shape', 'Margin', 'Density']\n",
    "imputer = IterativeImputer(max_iter=10, random_state=RANDOM_STATE)\n",
    "\n",
    "print(\"Starting MICE imputation...\")\n",
    "df_cleaned = df_raw.copy()\n",
    "df_cleaned[cols_to_impute] = imputer.fit_transform(df_raw[cols_to_impute])\n",
    "\n",
    "df_cleaned['BI-RADS'] = np.clip(df_cleaned['BI-RADS'], 1, 5)\n",
    "df_cleaned['Shape'] = np.clip(df_cleaned['Shape'], 1, 4)\n",
    "df_cleaned['Margin'] = np.clip(df_cleaned['Margin'], 1, 5)\n",
    "df_cleaned['Density'] = np.clip(df_cleaned['Density'], 1, 4)\n",
    "for col in cols_to_impute:\n",
    "    df_cleaned[col] = df_cleaned[col].round().astype(int)\n",
    "\n",
    "print(f\"Data cleaned and imputed. Shape: {df_cleaned.shape}\")\n",
    "print(\"\\nMissing values after imputation:\", df_cleaned.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a98170",
   "metadata": {},
   "source": [
    "# 3. Confirming Majority and Minority Classes\n",
    "#\n",
    "For our imbalance experiments, we need to clearly define the majority and minority classes.\n",
    "- **Class 0 (Majority):** Benign\n",
    "- **Class 1 (Minority):** Malignant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1b62bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable distribution:\n",
      "Severity\n",
      "0    516\n",
      "1    445\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Target variable distribution:\")\n",
    "print(df_cleaned[TARGET_FEATURE].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29b4c95",
   "metadata": {},
   "source": [
    "# 4. Create a Hold-Out Test Set\n",
    "\n",
    "We perform a one-time stratified split to create a final test set. All experimental datasets will be generated from the `train_full_df`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0683db2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full training set shape: (768, 6)\n",
      "Hold-out test set shape: (193, 5)\n"
     ]
    }
   ],
   "source": [
    "X = df_cleaned.drop(TARGET_FEATURE, axis=1)\n",
    "y = df_cleaned[[TARGET_FEATURE]]\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "train_full_df = pd.concat([X_train_full, y_train_full], axis=1)\n",
    "\n",
    "print(f\"Full training set shape: {train_full_df.shape}\")\n",
    "print(f\"Hold-out test set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e10097",
   "metadata": {},
   "source": [
    "# 5. Generate Imbalanced and Control Datasets with Multiple Repetitions\n",
    "\n",
    "For each IR, we now create multiple repetitions by sampling \n",
    "different subsets of the minority class. This allows us to test whether methods \n",
    "work reliably across different minority class samples.\n",
    "\n",
    "1.  Start with the **full majority class** ('Benign').\n",
    "2.  **Undersample the minority class** ('Malignant') to achieve the desired Imbalance Ratio (IR).\n",
    "3.  **Repeat this sampling N_REPETITIONS times** with different random seeds.\n",
    "4.  Create a size-matched **control dataset** for each IR and repetition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0eb0c1",
   "metadata": {},
   "source": [
    "\n",
    "  * **Methodology:** \"To generate datasets with varying degrees of class imbalance, the majority class was held constant at 412 samples while the minority class was progressively undersampled to achieve imbalance ratios from 5:1 to 100:1. It should be noted that this approach intrinsically links a higher imbalance ratio with a smaller number of minority class samples.\"\n",
    "  * **Discussion:** When interpreting your results, we can't claim that the degradation in synthetic data quality is *only* due to the imbalance ratio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05d09d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_full_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m malignant_df = \u001b[43mtrain_full_df\u001b[49m[train_full_df[TARGET_FEATURE] == \u001b[32m1\u001b[39m]\n\u001b[32m      2\u001b[39m benign_df = train_full_df[train_full_df[TARGET_FEATURE] == \u001b[32m0\u001b[39m]\n\u001b[32m      3\u001b[39m n_minority_available = \u001b[38;5;28mlen\u001b[39m(malignant_df)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_full_df' is not defined"
     ]
    }
   ],
   "source": [
    "malignant_df = train_full_df[train_full_df[TARGET_FEATURE] == 1]\n",
    "benign_df = train_full_df[train_full_df[TARGET_FEATURE] == 0]\n",
    "n_minority_available = len(malignant_df)\n",
    "n_majority_available = len(benign_df)\n",
    "\n",
    "print(f\"\\nFull training set composition: {n_majority_available} majority (Benign), {n_minority_available} minority (Malignant).\")\n",
    "print(f\"\\nGenerating datasets with {N_REPETITIONS} repetitions per imbalance ratio...\")\n",
    "\n",
    "generated_datasets = {}\n",
    "\n",
    "for ir in IMBALANCE_RATIOS:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing Imbalance Ratio (IR) = {ir}:1\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    for rep_id in range(1, N_REPETITIONS + 1):\n",
    "        print(f\"\\n  Repetition {rep_id}/{N_REPETITIONS}\")\n",
    "        \n",
    "        # Use different random seed for each repetition\n",
    "        rep_seed = RANDOM_STATE + (ir * 1000) + rep_id\n",
    "        \n",
    "        if ir == 1:\n",
    "            # For balanced case, undersample majority to match minority\n",
    "            majority_undersampled = resample(\n",
    "                benign_df,\n",
    "                replace=False,\n",
    "                n_samples=n_minority_available, \n",
    "                random_state=rep_seed \n",
    "            )\n",
    "            imbalanced_df = pd.concat([majority_undersampled, malignant_df])\n",
    "            \n",
    "        else:\n",
    "            majority_full_set = benign_df\n",
    "            \n",
    "            n_minority_imbalanced = int(n_majority_available / ir)\n",
    "\n",
    "            if n_minority_imbalanced > n_minority_available:\n",
    "                print(f\"    SKIPPING: Cannot create {ir}:1 ratio as it requires more minority samples than available.\")\n",
    "                continue\n",
    "            if n_minority_imbalanced < 1:\n",
    "                print(f\"    SKIPPING: Ratio {ir}:1 results in zero minority samples.\")\n",
    "                continue\n",
    "\n",
    "            # Sample different minority instances each repetition\n",
    "            minority_undersampled = resample(\n",
    "                malignant_df,\n",
    "                replace=False,\n",
    "                n_samples=n_minority_imbalanced,\n",
    "                random_state=rep_seed \n",
    "            )\n",
    "\n",
    "            imbalanced_df = pd.concat([majority_full_set, minority_undersampled])\n",
    "\n",
    "        total_size = len(imbalanced_df)\n",
    "        \n",
    "        # Store with repetition ID in the key\n",
    "        dataset_key = f'imbalanced_ir_{ir}_rep{rep_id}'\n",
    "        generated_datasets[dataset_key] = imbalanced_df\n",
    "        \n",
    "        n_maj = len(imbalanced_df[imbalanced_df[TARGET_FEATURE] == 0])\n",
    "        n_min = len(imbalanced_df[imbalanced_df[TARGET_FEATURE] == 1])\n",
    "        print(f\"    Imbalanced set created: {total_size} samples ({n_maj} majority, {n_min} minority)\")\n",
    "\n",
    "        if total_size >= len(train_full_df):\n",
    "            control_df = train_full_df.copy()\n",
    "        else:\n",
    "            control_df, _ = train_test_split(\n",
    "                train_full_df,\n",
    "                train_size=total_size,\n",
    "                random_state=rep_seed,  \n",
    "                stratify=train_full_df[TARGET_FEATURE]\n",
    "            )\n",
    "        \n",
    "        control_key = f'control_ir_{ir}_rep{rep_id}'\n",
    "        generated_datasets[control_key] = control_df\n",
    "        print(f\"    Control set created:      {len(control_df)} samples (original class ratio)\")\n",
    "\n",
    "print(f\"Dataset generation complete!\")\n",
    "print(f\"Total datasets created: {len(generated_datasets)}\")\n",
    "print(f\"  - Imbalanced: {len([k for k in generated_datasets.keys() if 'imbalanced' in k])}\")\n",
    "print(f\"  - Control: {len([k for k in generated_datasets.keys() if 'control' in k])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc40abf5",
   "metadata": {},
   "source": [
    "# 6. Preprocessing and Saving All Datasets\n",
    "\n",
    "We fit the scaler **once** on the full training data. Then, we transform all generated training sets and the hold-out test set using this single, consistent scaler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3b871e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling and saving datasets...\n",
      "\n",
      "Saved: train_imbalanced_ir_1_rep1.csv\n",
      "Saved: train_control_ir_1_rep1.csv\n",
      "Saved: train_imbalanced_ir_1_rep2.csv\n",
      "Saved: train_control_ir_1_rep2.csv\n",
      "Saved: train_imbalanced_ir_1_rep3.csv\n",
      "Saved: train_control_ir_1_rep3.csv\n",
      "Saved: train_imbalanced_ir_5_rep1.csv\n",
      "Saved: train_control_ir_5_rep1.csv\n",
      "Saved: train_imbalanced_ir_5_rep2.csv\n",
      "Saved: train_control_ir_5_rep2.csv\n",
      "Saved: train_imbalanced_ir_5_rep3.csv\n",
      "Saved: train_control_ir_5_rep3.csv\n",
      "Saved: train_imbalanced_ir_10_rep1.csv\n",
      "Saved: train_control_ir_10_rep1.csv\n",
      "Saved: train_imbalanced_ir_10_rep2.csv\n",
      "Saved: train_control_ir_10_rep2.csv\n",
      "Saved: train_imbalanced_ir_10_rep3.csv\n",
      "Saved: train_control_ir_10_rep3.csv\n",
      "Saved: train_imbalanced_ir_20_rep1.csv\n",
      "Saved: train_control_ir_20_rep1.csv\n",
      "Saved: train_imbalanced_ir_20_rep2.csv\n",
      "Saved: train_control_ir_20_rep2.csv\n",
      "Saved: train_imbalanced_ir_20_rep3.csv\n",
      "Saved: train_control_ir_20_rep3.csv\n",
      "Saved: train_imbalanced_ir_50_rep1.csv\n",
      "Saved: train_control_ir_50_rep1.csv\n",
      "Saved: train_imbalanced_ir_50_rep2.csv\n",
      "Saved: train_control_ir_50_rep2.csv\n",
      "Saved: train_imbalanced_ir_50_rep3.csv\n",
      "Saved: train_control_ir_50_rep3.csv\n",
      "Saved: train_imbalanced_ir_100_rep1.csv\n",
      "Saved: train_control_ir_100_rep1.csv\n",
      "Saved: train_imbalanced_ir_100_rep2.csv\n",
      "Saved: train_control_ir_100_rep2.csv\n",
      "Saved: train_imbalanced_ir_100_rep3.csv\n",
      "Saved: train_control_ir_100_rep3.csv\n",
      "Preprocessing complete. All datasets are ready for experiments.\n"
     ]
    }
   ],
   "source": [
    "FEATURES_TO_SCALE = ['BI-RADS', 'Age', 'Shape', 'Margin', 'Density']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_full[FEATURES_TO_SCALE])\n",
    "\n",
    "print(\"Scaling and saving datasets...\\n\")\n",
    "\n",
    "for name, df in generated_datasets.items():\n",
    "    X_temp = df.drop(columns=[TARGET_FEATURE])\n",
    "    y_temp = df[[TARGET_FEATURE]]\n",
    "\n",
    "    X_processed = scaler.transform(X_temp[FEATURES_TO_SCALE])\n",
    "    X_processed_df = pd.DataFrame(X_processed, columns=FEATURES_TO_SCALE)\n",
    "    \n",
    "    final_df = X_processed_df.reset_index(drop=True)\n",
    "    final_df[TARGET_FEATURE] = y_temp.reset_index(drop=True)\n",
    "    \n",
    "    save_path = PROCESSED_PATH / f\"train_{name}.csv\"\n",
    "    final_df.to_csv(save_path, index=False)\n",
    "    print(f\"Saved: {save_path.name}\")\n",
    "\n",
    "X_test_processed = scaler.transform(X_test[FEATURES_TO_SCALE])\n",
    "X_test_processed_df = pd.DataFrame(X_test_processed, columns=FEATURES_TO_SCALE)\n",
    "\n",
    "test_df = X_test_processed_df.reset_index(drop=True)\n",
    "test_df[TARGET_FEATURE] = y_test.reset_index(drop=True)\n",
    "test_df.to_csv(PROCESSED_PATH / \"test.csv\", index=False)\n",
    "\n",
    "print(\"Preprocessing complete. All datasets are ready for experiments.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
