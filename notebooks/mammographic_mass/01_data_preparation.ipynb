{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04a5d143",
   "metadata": {},
   "source": [
    "# 1. Data Loading and Initial Setup\n",
    "\n",
    "1.  Load and clean the raw data using MICE imputation.\n",
    "2.  Create a single, hold-out test set.\n",
    "3.  From the main training set, generate multiple training datasets with varying **imbalance ratios (IR)** by undersampling the majority class.\n",
    "4.  For each IR, create **multiple repetitions** with different random samples of the minority class.\n",
    "5.  For each IR and repetition, create a size-matched **control dataset** with the original class ratio.\n",
    "6.  Preprocess and save all generated datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cwj5xbttjzt",
   "metadata": {},
   "source": [
    "# Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4sld07nmkiq",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: mammographic_mass\n"
     ]
    }
   ],
   "source": [
    "# Set the dataset name - change this for different datasets\n",
    "DATASET_NAME = \"mammographic_mass\"\n",
    "\n",
    "print(f\"Dataset: {DATASET_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9894605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  • Dataset: mammographic_mass\n",
      "  • Raw data path: ../../data/raw/mammographic_mass.csv\n",
      "  • Processed data path: ../../data/processed/mammographic_mass\n",
      "  • Target feature: Severity\n",
      "\n",
      "Fetching and loading the raw dataset...\n",
      "Raw dataset loaded and saved. Shape: (961, 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.utils import resample\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(Path(\"../../src\").resolve()))\n",
    "from config import get_config\n",
    "\n",
    "config = get_config()\n",
    "\n",
    "# Setup paths based on dataset name\n",
    "RAW_PATH = Path(f\"../../data/raw/{DATASET_NAME}.csv\")\n",
    "PROCESSED_PATH = Path(f\"../../data/processed/{DATASET_NAME}/\")\n",
    "\n",
    "TARGET_FEATURE = \"Severity\"\n",
    "CLASS_BENIGN = 0\n",
    "CLASS_MALIGNANT = 1\n",
    "\n",
    "RANDOM_STATE = config.experiment.random_state\n",
    "IMBALANCE_RATIOS = config.experiment.imbalance_ratios\n",
    "N_REPETITIONS = config.experiment.n_repetitions\n",
    "\n",
    "RAW_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "PROCESSED_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  • Dataset: {DATASET_NAME}\")\n",
    "print(f\"  • Raw data path: {RAW_PATH}\")\n",
    "print(f\"  • Processed data path: {PROCESSED_PATH}\")\n",
    "print(f\"  • Target feature: {TARGET_FEATURE}\")\n",
    "print(f\"\\nFetching and loading the raw dataset...\")\n",
    "\n",
    "mammographic_mass = fetch_ucirepo(id=161)\n",
    "X_features = mammographic_mass.data.features\n",
    "y_target = mammographic_mass.data.targets\n",
    "df_raw = pd.concat([X_features, y_target], axis=1)\n",
    "df_raw.to_csv(RAW_PATH, index=False)\n",
    "print(f\"Raw dataset loaded and saved. Shape: {df_raw.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9e24a5",
   "metadata": {},
   "source": [
    "# 2. Data Cleaning: Imputing Missing Values\n",
    "\n",
    "As determined in the EDA, we use MICE to impute missing values to avoid introducing bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5534acab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting MICE imputation...\n",
      "Data cleaned and imputed. Shape: (961, 6)\n",
      "\n",
      "Missing values after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "cols_to_impute = ['BI-RADS', 'Age', 'Shape', 'Margin', 'Density']\n",
    "imputer = IterativeImputer(max_iter=10, random_state=RANDOM_STATE)\n",
    "\n",
    "print(\"Starting MICE imputation...\")\n",
    "df_cleaned = df_raw.copy()\n",
    "df_cleaned[cols_to_impute] = imputer.fit_transform(df_raw[cols_to_impute])\n",
    "\n",
    "df_cleaned['BI-RADS'] = np.clip(df_cleaned['BI-RADS'], 1, 5)\n",
    "df_cleaned['Shape'] = np.clip(df_cleaned['Shape'], 1, 4)\n",
    "df_cleaned['Margin'] = np.clip(df_cleaned['Margin'], 1, 5)\n",
    "df_cleaned['Density'] = np.clip(df_cleaned['Density'], 1, 4)\n",
    "\n",
    "for col in cols_to_impute:\n",
    "    df_cleaned[col] = df_cleaned[col].round().astype(int)\n",
    "\n",
    "print(f\"Data cleaned and imputed. Shape: {df_cleaned.shape}\")\n",
    "print(\"\\nMissing values after imputation:\", df_cleaned.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a98170",
   "metadata": {},
   "source": [
    "# 3. Confirming Majority and Minority Classes\n",
    "#\n",
    "For our imbalance experiments, we need to clearly define the majority and minority classes.\n",
    "- **Class 0 (Majority):** Benign\n",
    "- **Class 1 (Minority):** Malignant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb1b62bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable distribution:\n",
      "Severity\n",
      "0    516\n",
      "1    445\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Target variable distribution:\")\n",
    "print(df_cleaned[TARGET_FEATURE].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29b4c95",
   "metadata": {},
   "source": [
    "# 4. Create a Hold-Out Test Set\n",
    "\n",
    "We perform a one-time stratified split to create a final test set. All experimental datasets will be generated from the `train_full_df`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0683db2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full training set shape: (768, 6)\n",
      "Hold-out test set shape: (193, 5)\n"
     ]
    }
   ],
   "source": [
    "X = df_cleaned.drop(TARGET_FEATURE, axis=1)\n",
    "y = df_cleaned[[TARGET_FEATURE]]\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=config.experiment.test_size,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "train_full_df = pd.concat([X_train_full, y_train_full], axis=1)\n",
    "\n",
    "print(f\"Full training set shape: {train_full_df.shape}\")\n",
    "print(f\"Hold-out test set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e10097",
   "metadata": {},
   "source": [
    "# 5. Generate Imbalanced and Control Datasets with Multiple Repetitions\n",
    "\n",
    "For each IR, we now create multiple repetitions by sampling \n",
    "different subsets of the minority class. This allows us to test whether methods \n",
    "work reliably across different minority class samples.\n",
    "\n",
    "1.  Start with the **full majority class** ('Benign').\n",
    "2.  **Undersample the minority class** ('Malignant') to achieve the desired Imbalance Ratio (IR).\n",
    "3.  **Repeat this sampling N_REPETITIONS times** with different random seeds.\n",
    "4.  Create a size-matched **control dataset** for each IR and repetition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0eb0c1",
   "metadata": {},
   "source": [
    "\n",
    "  * **Methodology:** \"To generate datasets with varying degrees of class imbalance, the majority class was held constant at 412 samples while the minority class was progressively undersampled to achieve imbalance ratios from 5:1 to 100:1. It should be noted that this approach intrinsically links a higher imbalance ratio with a smaller number of minority class samples.\"\n",
    "  * **Discussion:** When interpreting your results, we can't claim that the degradation in synthetic data quality is *only* due to the imbalance ratio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e05d09d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full training set composition: 412 majority (Benign), 356 minority (Malignant).\n",
      "\n",
      "Generating datasets with 3 repetitions per imbalance ratio...\n",
      "\n",
      "\n",
      "Processing Imbalance Ratio (IR) = 1:1\n",
      "\n",
      "\n",
      "\n",
      "  Repetition 1/3\n",
      "    Imbalanced set created: 712 samples (356 majority, 356 minority)\n",
      "    Control set created:      712 samples (original class ratio)\n",
      "\n",
      "  Repetition 2/3\n",
      "    Imbalanced set created: 712 samples (356 majority, 356 minority)\n",
      "    Control set created:      712 samples (original class ratio)\n",
      "\n",
      "  Repetition 3/3\n",
      "    Imbalanced set created: 712 samples (356 majority, 356 minority)\n",
      "    Control set created:      712 samples (original class ratio)\n",
      "\n",
      "\n",
      "Processing Imbalance Ratio (IR) = 5:1\n",
      "\n",
      "\n",
      "\n",
      "  Repetition 1/3\n",
      "    Imbalanced set created: 494 samples (412 majority, 82 minority)\n",
      "    Control set created:      494 samples (original class ratio)\n",
      "\n",
      "  Repetition 2/3\n",
      "    Imbalanced set created: 494 samples (412 majority, 82 minority)\n",
      "    Control set created:      494 samples (original class ratio)\n",
      "\n",
      "  Repetition 3/3\n",
      "    Imbalanced set created: 494 samples (412 majority, 82 minority)\n",
      "    Control set created:      494 samples (original class ratio)\n",
      "\n",
      "\n",
      "Processing Imbalance Ratio (IR) = 10:1\n",
      "\n",
      "\n",
      "\n",
      "  Repetition 1/3\n",
      "    Imbalanced set created: 453 samples (412 majority, 41 minority)\n",
      "    Control set created:      453 samples (original class ratio)\n",
      "\n",
      "  Repetition 2/3\n",
      "    Imbalanced set created: 453 samples (412 majority, 41 minority)\n",
      "    Control set created:      453 samples (original class ratio)\n",
      "\n",
      "  Repetition 3/3\n",
      "    Imbalanced set created: 453 samples (412 majority, 41 minority)\n",
      "    Control set created:      453 samples (original class ratio)\n",
      "\n",
      "\n",
      "Processing Imbalance Ratio (IR) = 20:1\n",
      "\n",
      "\n",
      "\n",
      "  Repetition 1/3\n",
      "    Imbalanced set created: 432 samples (412 majority, 20 minority)\n",
      "    Control set created:      432 samples (original class ratio)\n",
      "\n",
      "  Repetition 2/3\n",
      "    Imbalanced set created: 432 samples (412 majority, 20 minority)\n",
      "    Control set created:      432 samples (original class ratio)\n",
      "\n",
      "  Repetition 3/3\n",
      "    Imbalanced set created: 432 samples (412 majority, 20 minority)\n",
      "    Control set created:      432 samples (original class ratio)\n",
      "\n",
      "\n",
      "Processing Imbalance Ratio (IR) = 50:1\n",
      "\n",
      "\n",
      "\n",
      "  Repetition 1/3\n",
      "    Imbalanced set created: 420 samples (412 majority, 8 minority)\n",
      "    Control set created:      420 samples (original class ratio)\n",
      "\n",
      "  Repetition 2/3\n",
      "    Imbalanced set created: 420 samples (412 majority, 8 minority)\n",
      "    Control set created:      420 samples (original class ratio)\n",
      "\n",
      "  Repetition 3/3\n",
      "    Imbalanced set created: 420 samples (412 majority, 8 minority)\n",
      "    Control set created:      420 samples (original class ratio)\n",
      "\n",
      "\n",
      "Processing Imbalance Ratio (IR) = 100:1\n",
      "\n",
      "\n",
      "\n",
      "  Repetition 1/3\n",
      "    Imbalanced set created: 416 samples (412 majority, 4 minority)\n",
      "    Control set created:      416 samples (original class ratio)\n",
      "\n",
      "  Repetition 2/3\n",
      "    Imbalanced set created: 416 samples (412 majority, 4 minority)\n",
      "    Control set created:      416 samples (original class ratio)\n",
      "\n",
      "  Repetition 3/3\n",
      "    Imbalanced set created: 416 samples (412 majority, 4 minority)\n",
      "    Control set created:      416 samples (original class ratio)\n",
      "Dataset generation complete!\n",
      "Total datasets created: 36\n",
      "  - Imbalanced: 18\n",
      "  - Control: 18\n"
     ]
    }
   ],
   "source": [
    "malignant_df = train_full_df[train_full_df[TARGET_FEATURE] == CLASS_MALIGNANT]\n",
    "benign_df = train_full_df[train_full_df[TARGET_FEATURE] == CLASS_BENIGN]\n",
    "n_minority_available = len(malignant_df)\n",
    "n_majority_available = len(benign_df)\n",
    "\n",
    "print(f\"\\nFull training set composition: {n_majority_available} majority (Benign), {n_minority_available} minority (Malignant).\")\n",
    "print(f\"\\nGenerating datasets with {N_REPETITIONS} repetitions per imbalance ratio...\")\n",
    "\n",
    "generated_datasets = {}\n",
    "\n",
    "for ir in IMBALANCE_RATIOS:\n",
    "    print(f\"\\n\")\n",
    "    print(f\"Processing Imbalance Ratio (IR) = {ir}:1\")\n",
    "    print(f\"\\n\")\n",
    "    \n",
    "    for rep_id in range(1, N_REPETITIONS + 1):\n",
    "        print(f\"\\n  Repetition {rep_id}/{N_REPETITIONS}\")\n",
    "        \n",
    "        # Use different random seed for each repetition\n",
    "        rep_seed = RANDOM_STATE + (ir * 1000) + rep_id\n",
    "        \n",
    "        if ir == 1:\n",
    "            majority_undersampled = resample(\n",
    "                benign_df,\n",
    "                replace=False,\n",
    "                n_samples=n_minority_available, \n",
    "                random_state=rep_seed \n",
    "            )\n",
    "            imbalanced_df = pd.concat([majority_undersampled, malignant_df])\n",
    "            \n",
    "        else:\n",
    "            majority_full_set = benign_df\n",
    "            \n",
    "            n_minority_imbalanced = int(n_majority_available / ir)\n",
    "\n",
    "            if n_minority_imbalanced > n_minority_available:\n",
    "                print(f\"    SKIPPING: Cannot create {ir}:1 ratio as it requires more minority samples than available.\")\n",
    "                continue\n",
    "            if n_minority_imbalanced < 1:\n",
    "                print(f\"    SKIPPING: Ratio {ir}:1 results in zero minority samples.\")\n",
    "                continue\n",
    "\n",
    "            minority_undersampled = resample(\n",
    "                malignant_df,\n",
    "                replace=False,\n",
    "                n_samples=n_minority_imbalanced,\n",
    "                random_state=rep_seed \n",
    "            )\n",
    "\n",
    "            imbalanced_df = pd.concat([majority_full_set, minority_undersampled])\n",
    "\n",
    "        total_size = len(imbalanced_df)\n",
    "        \n",
    "        dataset_key = f'imbalanced_ir_{ir}_rep{rep_id}'\n",
    "        generated_datasets[dataset_key] = imbalanced_df\n",
    "        \n",
    "        n_maj = len(imbalanced_df[imbalanced_df[TARGET_FEATURE] == CLASS_BENIGN])\n",
    "        n_min = len(imbalanced_df[imbalanced_df[TARGET_FEATURE] == CLASS_MALIGNANT])\n",
    "        print(f\"    Imbalanced set created: {total_size} samples ({n_maj} majority, {n_min} minority)\")\n",
    "\n",
    "        if total_size >= len(train_full_df):\n",
    "            control_df = train_full_df.copy()\n",
    "        else:\n",
    "            control_df, _ = train_test_split(\n",
    "                train_full_df,\n",
    "                train_size=total_size,\n",
    "                random_state=rep_seed,  \n",
    "                stratify=train_full_df[TARGET_FEATURE]\n",
    "            )\n",
    "        \n",
    "        control_key = f'control_ir_{ir}_rep{rep_id}'\n",
    "        generated_datasets[control_key] = control_df\n",
    "        print(f\"    Control set created:      {len(control_df)} samples (original class ratio)\")\n",
    "\n",
    "print(f\"Dataset generation complete!\")\n",
    "print(f\"Total datasets created: {len(generated_datasets)}\")\n",
    "print(f\"  - Imbalanced: {len([k for k in generated_datasets.keys() if 'imbalanced' in k])}\")\n",
    "print(f\"  - Control: {len([k for k in generated_datasets.keys() if 'control' in k])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc40abf5",
   "metadata": {},
   "source": [
    "# 6. Preprocessing and Saving All Datasets\n",
    "\n",
    "We fit the scaler **once** on the full training data. Then, we transform all generated training sets and the hold-out test set using this single, consistent scaler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd3b871e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling and saving datasets...\n",
      "\n",
      "Saved: train_imbalanced_ir_1_rep1.csv\n",
      "Saved: train_control_ir_1_rep1.csv\n",
      "Saved: train_imbalanced_ir_1_rep2.csv\n",
      "Saved: train_control_ir_1_rep2.csv\n",
      "Saved: train_imbalanced_ir_1_rep3.csv\n",
      "Saved: train_control_ir_1_rep3.csv\n",
      "Saved: train_imbalanced_ir_5_rep1.csv\n",
      "Saved: train_control_ir_5_rep1.csv\n",
      "Saved: train_imbalanced_ir_5_rep2.csv\n",
      "Saved: train_control_ir_5_rep2.csv\n",
      "Saved: train_imbalanced_ir_5_rep3.csv\n",
      "Saved: train_control_ir_5_rep3.csv\n",
      "Saved: train_imbalanced_ir_10_rep1.csv\n",
      "Saved: train_control_ir_10_rep1.csv\n",
      "Saved: train_imbalanced_ir_10_rep2.csv\n",
      "Saved: train_control_ir_10_rep2.csv\n",
      "Saved: train_imbalanced_ir_10_rep3.csv\n",
      "Saved: train_control_ir_10_rep3.csv\n",
      "Saved: train_imbalanced_ir_20_rep1.csv\n",
      "Saved: train_control_ir_20_rep1.csv\n",
      "Saved: train_imbalanced_ir_20_rep2.csv\n",
      "Saved: train_control_ir_20_rep2.csv\n",
      "Saved: train_imbalanced_ir_20_rep3.csv\n",
      "Saved: train_control_ir_20_rep3.csv\n",
      "Saved: train_imbalanced_ir_50_rep1.csv\n",
      "Saved: train_control_ir_50_rep1.csv\n",
      "Saved: train_imbalanced_ir_50_rep2.csv\n",
      "Saved: train_control_ir_50_rep2.csv\n",
      "Saved: train_imbalanced_ir_50_rep3.csv\n",
      "Saved: train_control_ir_50_rep3.csv\n",
      "Saved: train_imbalanced_ir_100_rep1.csv\n",
      "Saved: train_control_ir_100_rep1.csv\n",
      "Saved: train_imbalanced_ir_100_rep2.csv\n",
      "Saved: train_control_ir_100_rep2.csv\n",
      "Saved: train_imbalanced_ir_100_rep3.csv\n",
      "Saved: train_control_ir_100_rep3.csv\n",
      "\n",
      "Saved test set: test.csv\n",
      "Total training files: 36\n"
     ]
    }
   ],
   "source": [
    "FEATURES_TO_SCALE = ['BI-RADS', 'Age', 'Shape', 'Margin', 'Density']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_full[FEATURES_TO_SCALE])\n",
    "\n",
    "print(\"Scaling and saving datasets...\\n\")\n",
    "\n",
    "for name, df in generated_datasets.items():\n",
    "    X_temp = df.drop(columns=[TARGET_FEATURE])\n",
    "    y_temp = df[[TARGET_FEATURE]]\n",
    "\n",
    "    X_processed = scaler.transform(X_temp[FEATURES_TO_SCALE])\n",
    "    X_processed_df = pd.DataFrame(X_processed, columns=FEATURES_TO_SCALE)\n",
    "    \n",
    "    final_df = X_processed_df.reset_index(drop=True)\n",
    "    final_df[TARGET_FEATURE] = y_temp.reset_index(drop=True)\n",
    "    \n",
    "    save_path = PROCESSED_PATH / f\"train_{name}.csv\"\n",
    "    final_df.to_csv(save_path, index=False)\n",
    "    print(f\"Saved: {save_path.name}\")\n",
    "\n",
    "X_test_processed = scaler.transform(X_test[FEATURES_TO_SCALE])\n",
    "X_test_processed_df = pd.DataFrame(X_test_processed, columns=FEATURES_TO_SCALE)\n",
    "\n",
    "test_df = X_test_processed_df.reset_index(drop=True)\n",
    "test_df[TARGET_FEATURE] = y_test.reset_index(drop=True)\n",
    "test_df.to_csv(PROCESSED_PATH / \"test.csv\", index=False)\n",
    "\n",
    "print(f\"\\nSaved test set: test.csv\")\n",
    "print(f\"Total training files: {len(generated_datasets)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "wkcp9f4qtmq",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata saved to: ../../data/processed/mammographic_mass/metadata.json\n",
      "\n",
      "Processing complete! All datasets are ready for experiments.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Save metadata about this dataset processing\n",
    "metadata = {\n",
    "    \"dataset_name\": DATASET_NAME,\n",
    "    \"target_feature\": TARGET_FEATURE,\n",
    "    \"processing_timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"n_train_files\": len(generated_datasets),\n",
    "    \"imbalance_ratios\": IMBALANCE_RATIOS,\n",
    "    \"n_repetitions\": N_REPETITIONS,\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "    \"test_size\": len(test_df),\n",
    "    \"features\": FEATURES_TO_SCALE\n",
    "}\n",
    "\n",
    "metadata_path = PROCESSED_PATH / \"metadata.json\"\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"\\nMetadata saved to: {metadata_path}\")\n",
    "print(\"\\nProcessing complete! All datasets are ready for experiments.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
